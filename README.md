# ğŸ¦ Tai Park Wildlife Classification - Usage Guide

Este sistema modular replica **exactamente** la lÃ³gica exitosa de tu notebook, pero organizada en mÃ³dulos reutilizables y escalables.

## ğŸš€ Quick Start

### 1. Ejecutar Training Completo (Replica del Notebook)

```bash
# Entrenar exactamente como el notebook
python scripts/train_notebook_style.py

# Con parÃ¡metros personalizados
python scripts/train_notebook_style.py \
    --data_dir data/raw \
    --num_epochs 5 \
    --batch_size 64 \
    --fraction 1.0 \
    --random_state 1
```

### 2. Test RÃ¡pido para Desarrollo

```bash
# Test rÃ¡pido con 10% de datos y 1 Ã©poca
python scripts/train_notebook_style.py --quick_test
```

## ğŸ“‹ Estructura del Sistema

```
tai-park-classifier/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ dataset.py          # âœ… Dataset con split por sitios
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ model.py            # âœ… ResNet152 + clasificaciÃ³n head
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py          # âœ… Training loop completo
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ helpers.py          # âœ… VisualizaciÃ³n y anÃ¡lisis
â””â”€â”€ scripts/
    â””â”€â”€ train_notebook_style.py # âœ… Script principal
```

## ğŸ¯ Funcionalidades Implementadas

### âœ… Exactamente del Notebook:
- **Dataset Loading**: `train_features.csv`, `train_labels.csv`, `test_features.csv`
- **Preprocessing**: `custom_preprocessing()` con color, brillo, contraste
- **Augmentation**: `data_augmentation()` con rotaciÃ³n, flip, color jitter
- **Model**: ResNet152 con solo layer4 descongelado
- **Training Head**: Linear(2048â†’1024â†’256â†’8) con BatchNorm y Dropout
- **Optimizer**: SGD (lr=0.01, momentum=0.909431, weight_decay=0.005)
- **Scheduler**: ReduceLROnPlateau (patience=2, factor=0.72)
- **Early Stopping**: Custom logic con tolerance=5
- **Loss Tracking**: EvaluaciÃ³n en quarter-steps
- **Dataset Recreation**: Cada Ã©poca recrea dataset con augmentation

### âœ… Mejoras Implementadas:
- **ğŸš¨ Split por Sitios**: Evita data leakage (el notebook usaba stratified split)
- **ğŸ“ Estructura Modular**: CÃ³digo organizado y reutilizable
- **ğŸ“Š Visualizaciones**: DistribuciÃ³n de clases, sitios, samples
- **ğŸ” AnÃ¡lisis Detallado**: MÃ©tricas completas, confusion matrix
- **ğŸ’¾ Checkpoints**: Guardado automÃ¡tico del mejor modelo
- **ğŸ“ˆ Plots**: Loss curves automÃ¡ticos como el notebook

## ğŸ”§ Uso ProgramÃ¡tico

### Entrenamiento Personalizado

```python
from src.data.dataset import TaiParkDatasetNotebookStyle
from src.models.model import create_notebook_model
from src.training.trainer import create_notebook_trainer
from src.utils.helpers import notebook_style_summary

# 1. Crear dataset manager (replica notebook)
dataset_manager = TaiParkDatasetNotebookStyle(
    data_dir="data/raw",
    fraction=1.0,              # frac del notebook
    random_state=1,            # random_state del notebook
    use_preprocessing=True,    # custom_preprocessing
    use_augmentation=True,     # data_augmentation  
    num_augmentations=2        # create_combined_dataset
)

# 2. Crear modelo (replica notebook)
model = create_notebook_model()

# 3. Crear trainer (replica notebook)
trainer = create_notebook_trainer(model, dataset_manager)

# 4. Entrenar (replica notebook)
loss_history = trainer.train(
    num_epochs=5,
    batch_size=64
)

# 5. Mostrar resumen como notebook
notebook_style_summary(trainer, dataset_manager, model_info, loss_history)
```

### Crear Dataset para Inferencia

```python
from src.data.dataset import create_test_dataloader_notebook_style

# Test dataset para submissions
test_dataloader = create_test_dataloader_notebook_style(
    data_dir="data/raw",
    batch_size=64
)

# Generar submission
from src.utils.helpers import create_submission_file

submission = create_submission_file(
    model=model,
    test_dataloader=test_dataloader,
    class_names=dataset_manager.species_labels,
    device=trainer.device,
    output_path="data/submissions/my_submission.csv"
)
```

### AnÃ¡lisis y VisualizaciÃ³n

```python
from src.utils.helpers import (
    visualize_samples, 
    plot_class_distribution,
    plot_site_distribution,
    evaluate_model
)

# Visualizar muestras como notebook
visualize_samples(dataset_manager, save_path="results/plots/samples.png")

# DistribuciÃ³n de clases
plot_class_distribution(dataset_manager, save_path="results/plots/classes.png")

# Verificar split por sitios (no overlap)
no_leakage = plot_site_distribution(dataset_manager, save_path="results/plots/sites.png")
print(f"Sin data leakage: {no_leakage}")

# EvaluaciÃ³n completa del modelo
eval_results = evaluate_model(
    model=trainer.model,
    dataloader=eval_dataloader,
    device=trainer.device,
    class_names=dataset_manager.species_labels
)

print(f"Accuracy: {eval_results['accuracy']:.4f}")
print(f"Log Loss: {eval_results['log_loss']:.4f}")
```

## ğŸ›ï¸ ParÃ¡metros de ConfiguraciÃ³n

### Dataset Parameters

```python
TaiParkDatasetNotebookStyle(
    data_dir="data/raw",           # Carpeta con CSVs e imÃ¡genes
    fraction=1.0,                  # FracciÃ³n de datos (notebook: frac)
    random_state=1,                # Seed (notebook usa 1)
    validation_sites_file=None,    # CSV con sitios de validaciÃ³n
    test_size=0.25,                # TamaÃ±o split validaciÃ³n
    use_preprocessing=True,        # custom_preprocessing()
    use_augmentation=True,         # data_augmentation()
    num_augmentations=2            # Notebooks usa 2
)
```

### Model Parameters

```python
create_notebook_model()           # ConfiguraciÃ³n exacta del notebook

# O personalizado:
WildlifeClassifier(
    model_name='resnet152',        # resnet152, resnet50, efficientnet_b3, etc.
    num_classes=8,                 # 8 especies + blank
    pretrained=True,               # Usar pesos ImageNet
    freeze_layers=True,            # Congelar capas
    unfreeze_layers=['layer4'],    # Solo layer4 entrenable (notebook)
    dropout_rates=(0.5, 0.3),      # Dropout en head (notebook)
    hidden_sizes=(1024, 256)       # TamaÃ±os hidden layers (notebook)
)
```

### Training Parameters

```python
trainer.train(
    num_epochs=5,                  # Ã‰pocas mÃ¡ximas
    batch_size=64,                 # Batch size (notebook)
    save_best_model=True           # Cargar mejor modelo al final
)

# Optimizer (automÃ¡tico, igual al notebook):
# SGD(lr=0.01, momentum=0.909431, weight_decay=0.005)

# Scheduler (automÃ¡tico, igual al notebook):
# ReduceLROnPlateau(patience=2, factor=0.72)

# Early Stopping (automÃ¡tico, igual al notebook):
# min_delta=0.0001, tolerance=5
```

## ğŸ“Š Outputs Generados

### Modelos y Checkpoints
```
results/models/
â”œâ”€â”€ notebook_style_model.pth      # Mejor modelo entrenado
â””â”€â”€ checkpoint_epoch_X.pth        # Checkpoints por Ã©poca
```

### Visualizaciones
```
results/plots/
â”œâ”€â”€ loss_curves.png               # Training/eval loss (como notebook)
â”œâ”€â”€ sample_images.png             # Muestras por especie
â”œâ”€â”€ class_distribution.png        # DistribuciÃ³n de clases
â”œâ”€â”€ site_distribution.png         # DistribuciÃ³n de sitios
â””â”€â”€ confusion_matrix.png          # Matriz de confusiÃ³n
```

### Submissions
```
data/submissions/
â””â”€â”€ submission_YYYY-MM-DD.csv     # Archivo para competiciÃ³n
```

## ğŸ” Diferencias vs Notebook Original

### âœ… Mejoras Implementadas:

1. **ğŸš¨ CRÃTICO - Split por Sitios**: 
   - âŒ Notebook: `train_test_split(stratify=y)` â†’ Data leakage
   - âœ… Nuevo: Split por sitios completos â†’ Sin data leakage

2. **ğŸ“ CÃ³digo Modular**:
   - âŒ Notebook: Todo en celdas mezcladas
   - âœ… Nuevo: MÃ³dulos separados y reutilizables

3. **ğŸ” AnÃ¡lisis Mejorado**:
   - âœ… VerificaciÃ³n automÃ¡tica de data leakage
   - âœ… MÃ©tricas detalladas (accuracy, log loss, confusion matrix)
   - âœ… AnÃ¡lisis por sitios y clases

4. **ğŸ’¾ GestiÃ³n de Modelos**:
   - âœ… Guardado automÃ¡tico del mejor modelo
   - âœ… Checkpoints con configuraciÃ³n completa
   - âœ… Carga fÃ¡cil para inferencia

### ğŸ¯ Funcionalidades Preservadas:

- âœ… **Preprocessing exacto**: `custom_preprocessing()` idÃ©ntico
- âœ… **Augmentation exacto**: `data_augmentation()` idÃ©ntico  
- âœ… **Arquitectura exacta**: ResNet152 + head personalizado
- âœ… **Training loop exacto**: Early stopping, scheduler, evaluaciÃ³n en quarter-steps
- âœ… **HiperparÃ¡metros exactos**: lr, momentum, weight_decay del notebook
- âœ… **Dataset recreation**: Cada Ã©poca recrea dataset con augmentation
- âœ… **Loss tracking exacto**: Mismo formato que notebook

## ğŸš€ Comandos Ãštiles

### Training Completo
```bash
# Entrenamiento completo como notebook
python scripts/train_notebook_style.py \
    --num_epochs 5 \
    --batch_size 64 \
    --save_model_path results/models/my_model.pth

# Con validaciÃ³n por sitios especÃ­ficos
python scripts/train_notebook_style.py \
    --validation_sites_file data/processed/validation_sites.csv
```

### ExperimentaciÃ³n
```bash
# Experimento rÃ¡pido (10% datos, 1 Ã©poca)
python scripts/train_notebook_style.py \
    --fraction 0.1 \
    --num_epochs 1 \
    --batch_size 32

# Sin data augmentation (solo para testing)
python scripts/train_notebook_style.py \
    --num_augmentations 0
```

### Diferentes Modelos
```python
# ResNet50 en lugar de ResNet152
model = create_model(
    model_name='resnet50',
    num_classes=8,
    pretrained=True
)

# EfficientNet-B3  
model = create_model(
    model_name='efficientnet_b3',
    num_classes=8,
    pretrained=True
)
```

## ğŸ¯ PrÃ³ximos Pasos

1. **Ejecutar training completo**:
   ```bash
   python scripts/train_notebook_style.py
   ```

2. **Verificar resultados**:
   - Revisa `results/plots/loss_curves.png`
   - Verifica que no hay data leakage en site distribution
   - Compara loss final con tu notebook

3. **Generar submission**:
   ```python
   # Cargar modelo entrenado y crear submission
   submission = create_submission_file(...)
   ```

4. **Experimentar con variaciones**:
   - Diferentes arquitecturas (EfficientNet, etc.)
   - Diferentes hiperparÃ¡metros
   - Ensembles de modelos

## âš¡ Tips de Rendimiento

- **GPU Memory**: Si tienes problemas de memoria, reduce `batch_size`
- **Speed**: Para desarrollo rÃ¡pido, usa `--fraction 0.1`
- **Reproducibilidad**: Siempre usa el mismo `random_state`
- **Monitoring**: Los logs te muestran progreso detallado

Â¡El sistema estÃ¡ listo para replicar y mejorar tus resultados del notebook! ğŸš€