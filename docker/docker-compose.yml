services:
  wildlife-classifier:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: tai-park-classifier
    
    # GPU support (uncomment if you have NVIDIA GPU)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    volumes:
      # Mount the entire project
      - ..:/workspace
      # Mount data directory (read-only for safety)
      - ../data:/workspace/data:ro
      # Mount results directory (read-write)
      - ../results:/workspace/results
      # Cache directories for faster rebuilds
      - wildlife_pip_cache:/root/.cache/pip
      - wildlife_conda_cache:/opt/conda/pkgs
    
    ports:
      # Jupyter Lab
      - "8888:8888"
      # TensorBoard
      - "6006:6006"
      # Weights & Biases local server (if needed)
      - "8097:8097"
    
    environment:
      # Python environment
      - PYTHONPATH=/workspace
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      
      # CUDA settings (adjust based on your GPU)
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # Weights & Biases (uncomment and add your API key)
      # - WANDB_API_KEY=your_wandb_api_key_here
      # - WANDB_PROJECT=tai-park-species-classification
      
      # Other useful environment variables
      - TORCH_HOME=/workspace/.cache/torch
      - HF_HOME=/workspace/.cache/huggingface
      
      # Development settings
      - JUPYTER_ENABLE_LAB=yes
      
    working_dir: /workspace
    
    # Keep container running
    tty: true
    stdin_open: true
    
    # Restart policy
    restart: unless-stopped
    
    # Health check
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; assert torch.cuda.is_available()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Optional: TensorBoard service (if you want it separate)
  tensorboard:
    image: tensorflow/tensorflow:latest
    container_name: tai-park-tensorboard
    ports:
      - "6007:6006"
    volumes:
      - ../results/logs:/logs
    command: tensorboard --logdir=/logs --host=0.0.0.0 --port=6006
    profiles:
      - tensorboard

volumes:
  # Persistent volumes for caching
  wildlife_pip_cache:
    driver: local
  wildlife_conda_cache:
    driver: local

networks:
  default:
    name: wildlife-classification-net